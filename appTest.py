import streamlit as st
import pandas as pd
import joblib
import gdown
import tensorflow as tf
import os

# === Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ù„ÙØ§Øª Ø¹Ù„Ù‰ Google Drive ===
files = {
    "best_ml_model.pkl": "https://drive.google.com/uc?id=1Hrj1_EKfwqozCTM0FaVi82Qg1nnyfThn",
    "preprocessor.pkl": "https://drive.google.com/uc?id=1ZyiR3ZiGNXzDihWBuTTIK8PnTa-C0Ew_",
    "nn_model.h5": "https://drive.google.com/uc?id=13eoCKB9sk3JqPq0qIynO05E_m1y5ebTU",
    "zomato_sample.csv": "https://drive.google.com/uc?id=1U3CMhKvQ2_lOaFKVpFQVDxrr6hV4UE_Z"
}

# === ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø© ===
for filename, url in files.items():
    if not os.path.exists(filename):
        st.write(f"Downloading {filename}...")
        gdown.download(url, filename, quiet=False)

# === ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ ===
preprocessor = joblib.load("preprocessor.pkl")
best_model = joblib.load("best_ml_model.pkl")
nn_model = tf.keras.models.load_model("nn_model.h5")

# === ÙˆØ§Ø¬Ù‡Ø© Streamlit ===
st.title("ğŸ½ Zomato Restaurant Prediction App")

uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])
if uploaded_file is not None:
    data = pd.read_csv(uploaded_file)
else:
    st.info("Using sample dataset")
    data = pd.read_csv("zomato_sample.csv")

st.write("### Preview Data", data.head())

# === ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ===
processed_data = preprocessor.transform(data)

# === ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ===
ml_preds = best_model.predict(processed_data)
nn_preds = nn_model.predict(processed_data)

st.write("### ML Model Predictions", ml_preds)
st.write("### NN Model Predictions", nn_preds)
